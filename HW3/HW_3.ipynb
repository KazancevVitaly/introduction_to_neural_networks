{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28160c06",
   "metadata": {},
   "source": [
    "# GEEK BRAINS\n",
    "## Введение в нейронные сети\n",
    "## ДЗ Урока 3\n",
    "### Виталий Казанцев"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e4d4b",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "\n",
    "1. Попробуйте улучшить работу нейронной сети(разобранную на уроке) обучавшейся на датасет Fashion-MNIST. \n",
    "       Опишите в комментарии к уроку - какого результата вы добились от нейросети? Что помогло вам улучшить ее точность?\n",
    "\n",
    "    \n",
    "2. Поработайте с документацией TensorFlow 2. Попробуйте найти полезные команды TensorFlow неразобранные на уроке.\n",
    "        \n",
    "*3. Попробуйте обучить нейронную сеть на TensorFlow 2 на датасете imdb_reviews. Опишите в комментарии к уроку - какой результата вы добились от нейросети? Что помогло вам улучшить ее точность? </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb8ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 12:43:03.218376: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622936e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357d4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ccd3c1",
   "metadata": {},
   "source": [
    "#### Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5716c2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e28c1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2cddeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ea7c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df114963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d7c13",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38487132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[2500])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173a17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f7012",
   "metadata": {},
   "source": [
    "#### Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d08d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 12:43:05.542954: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f728d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6da896a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4996 - accuracy: 0.8254\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 2s 975us/step - loss: 0.3808 - accuracy: 0.8621\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 2s 967us/step - loss: 0.3396 - accuracy: 0.8759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5bfc431f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3697d35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.3660 - accuracy: 0.8712 - 288ms/epoch - 919us/step\n",
      "\n",
      "Test accuracy: 0.8712000250816345\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb282d",
   "metadata": {},
   "source": [
    "Эта модель, которую мы построили на уроке, оценка accuracy данной модели 0.87. Попробуем улучшить данную модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b6b610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(layers, neuro=128):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(neuro, activation='relu'),\n",
    "    ])\n",
    "\n",
    "    for _ in range(layers):        \n",
    "        model.add(keras.layers.Dense(neuro, activation='tanh'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit(train_images, train_labels, epochs=3, validation_split=0.2)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc31566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_10 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitaly/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4903 - accuracy: 0.8218 - val_loss: 0.4161 - val_accuracy: 0.8412\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3675 - accuracy: 0.8657 - val_loss: 0.3611 - val_accuracy: 0.8658\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3272 - accuracy: 0.8780 - val_loss: 0.3415 - val_accuracy: 0.8754\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_11 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,794\n",
      "Trainable params: 134,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4911 - accuracy: 0.8185 - val_loss: 0.4051 - val_accuracy: 0.8431\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3695 - accuracy: 0.8621 - val_loss: 0.3738 - val_accuracy: 0.8606\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3354 - accuracy: 0.8741 - val_loss: 0.3737 - val_accuracy: 0.8618\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_12 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,306\n",
      "Trainable params: 151,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4955 - accuracy: 0.8200 - val_loss: 0.4204 - val_accuracy: 0.8434\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3790 - accuracy: 0.8587 - val_loss: 0.3773 - val_accuracy: 0.8641\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3458 - accuracy: 0.8709 - val_loss: 0.3509 - val_accuracy: 0.8744\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_13 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,818\n",
      "Trainable params: 167,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5013 - accuracy: 0.8143 - val_loss: 0.4279 - val_accuracy: 0.8378\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3877 - accuracy: 0.8571 - val_loss: 0.4101 - val_accuracy: 0.8552\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3556 - accuracy: 0.8684 - val_loss: 0.3622 - val_accuracy: 0.8702\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_14 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,330\n",
      "Trainable params: 184,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5133 - accuracy: 0.8118 - val_loss: 0.4497 - val_accuracy: 0.8432\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4000 - accuracy: 0.8544 - val_loss: 0.3927 - val_accuracy: 0.8615\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3621 - accuracy: 0.8682 - val_loss: 0.3849 - val_accuracy: 0.8616\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_15 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 128)               16512     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_171 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,842\n",
      "Trainable params: 200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5250 - accuracy: 0.8108 - val_loss: 0.4642 - val_accuracy: 0.8388\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4082 - accuracy: 0.8536 - val_loss: 0.3835 - val_accuracy: 0.8648\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3751 - accuracy: 0.8639 - val_loss: 0.3813 - val_accuracy: 0.8643\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_16 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 217,354\n",
      "Trainable params: 217,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5332 - accuracy: 0.8075 - val_loss: 0.5225 - val_accuracy: 0.7927\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4223 - accuracy: 0.8486 - val_loss: 0.4567 - val_accuracy: 0.8335\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3845 - accuracy: 0.8620 - val_loss: 0.3893 - val_accuracy: 0.8612\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_17 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 233,866\n",
      "Trainable params: 233,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5521 - accuracy: 0.8021 - val_loss: 0.4543 - val_accuracy: 0.8430\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4371 - accuracy: 0.8425 - val_loss: 0.4597 - val_accuracy: 0.8403\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3984 - accuracy: 0.8580 - val_loss: 0.4210 - val_accuracy: 0.8509\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_18 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 250,378\n",
      "Trainable params: 250,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 5s 2ms/step - loss: 0.5723 - accuracy: 0.7944 - val_loss: 0.5474 - val_accuracy: 0.7983\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.4497 - accuracy: 0.8401 - val_loss: 0.4127 - val_accuracy: 0.8583\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4159 - accuracy: 0.8522 - val_loss: 0.4060 - val_accuracy: 0.8599\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flatten_19 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_214 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_215 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,890\n",
      "Trainable params: 266,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5780 - accuracy: 0.7949 - val_loss: 0.5197 - val_accuracy: 0.8225\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.4621 - accuracy: 0.8372 - val_loss: 0.6514 - val_accuracy: 0.7969\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.4406 - accuracy: 0.8459 - val_loss: 0.4314 - val_accuracy: 0.8493\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_20 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_216 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_217 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_218 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_219 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_220 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_224 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_225 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_228 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 283,402\n",
      "Trainable params: 283,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6012 - accuracy: 0.7874 - val_loss: 0.5436 - val_accuracy: 0.8213\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4830 - accuracy: 0.8344 - val_loss: 0.4579 - val_accuracy: 0.8374\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4614 - accuracy: 0.8388 - val_loss: 0.4672 - val_accuracy: 0.8378\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_21 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_229 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_235 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_236 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_237 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_238 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 299,914\n",
      "Trainable params: 299,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6319 - accuracy: 0.7770 - val_loss: 0.5350 - val_accuracy: 0.8164\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5019 - accuracy: 0.8259 - val_loss: 0.5704 - val_accuracy: 0.7954\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4758 - accuracy: 0.8369 - val_loss: 0.4726 - val_accuracy: 0.8378\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_22 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_243 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_244 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_245 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_246 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_247 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_255 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_256 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 316,426\n",
      "Trainable params: 316,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6470 - accuracy: 0.7733 - val_loss: 0.6070 - val_accuracy: 0.7635\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5662 - accuracy: 0.8104 - val_loss: 0.6056 - val_accuracy: 0.7871\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.7450 - accuracy: 0.7320 - val_loss: 0.9052 - val_accuracy: 0.6186\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_23 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_261 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_262 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_263 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_264 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_265 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_270 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_271 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_272 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_273 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332,938\n",
      "Trainable params: 332,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6860 - accuracy: 0.7567 - val_loss: 0.4954 - val_accuracy: 0.8324\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6341 - accuracy: 0.7816 - val_loss: 0.7132 - val_accuracy: 0.7646\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6450 - accuracy: 0.7750 - val_loss: 0.6463 - val_accuracy: 0.7767\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_24 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_274 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_275 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_276 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_277 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_278 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_279 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_280 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_281 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_282 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_283 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_284 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_285 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_286 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_287 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_288 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_289 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 10)                1290      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 349,450\n",
      "Trainable params: 349,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.7554 - accuracy: 0.7281 - val_loss: 0.6931 - val_accuracy: 0.7869\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.9870 - accuracy: 0.6273 - val_loss: 1.3340 - val_accuracy: 0.4369\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.8350 - accuracy: 0.2576 - val_loss: 2.0528 - val_accuracy: 0.1902\n"
     ]
    }
   ],
   "source": [
    "layers = np.arange(1, 16)\n",
    "for l in layers:\n",
    "    make_model(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367cb32",
   "metadata": {},
   "source": [
    "Наилучший результат дает модель из 4х слоев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "344b414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimiser=SGD\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_36 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.8070 - accuracy: 0.7326 - val_loss: 0.5736 - val_accuracy: 0.7976\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5170 - accuracy: 0.8206 - val_loss: 0.4841 - val_accuracy: 0.8290\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4670 - accuracy: 0.8371 - val_loss: 0.4759 - val_accuracy: 0.8287\n",
      "**************************************************\n",
      "Optimiser=RMSProp\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_37 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5129 - accuracy: 0.8148 - val_loss: 0.4053 - val_accuracy: 0.8503\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3813 - accuracy: 0.8631 - val_loss: 0.3879 - val_accuracy: 0.8622\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3548 - accuracy: 0.8738 - val_loss: 0.3586 - val_accuracy: 0.8742\n",
      "**************************************************\n",
      "Optimiser=adam\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_38 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5058 - accuracy: 0.8194 - val_loss: 0.4035 - val_accuracy: 0.8547\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3720 - accuracy: 0.8631 - val_loss: 0.3719 - val_accuracy: 0.8664\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3338 - accuracy: 0.8771 - val_loss: 0.3679 - val_accuracy: 0.8681\n",
      "**************************************************\n",
      "Optimiser=NAdam\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_39 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4944 - accuracy: 0.8256 - val_loss: 0.4180 - val_accuracy: 0.8499\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3616 - accuracy: 0.8670 - val_loss: 0.3567 - val_accuracy: 0.8723\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3260 - accuracy: 0.8804 - val_loss: 0.3400 - val_accuracy: 0.8750\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.save_weights('model.two')\n",
    "plt.figure(figsize=(16,7))\n",
    "\n",
    "for i_optim in ['SGD', 'RMSProp', 'adam', 'NAdam']:\n",
    "    modeli = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    modeli.load_weights('model.two')\n",
    "    \n",
    "    modeli.compile(optimizer=i_optim,\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    print(f'Optimiser={i_optim}')\n",
    "    modeli.summary()\n",
    "    modeli.fit(train_images, train_labels, epochs=3, validation_split=0.2)\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b521f3",
   "metadata": {},
   "source": [
    "Таким образом представленную модель можно улучшить добавлением одного дополнительного слоя и использованием Nadam оптимизатора."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
